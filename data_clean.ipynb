{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des colonnes 'inutiles' , et lignes comportant des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes supprimées de : 2017-05-12_3_6C-80per_3_6C_CH2.csv\n",
      "Colonnes supprimées de : 2017-05-12_3_6C-80per_3_6C_CH3.csv\n",
      "Colonnes supprimées de : 2017-05-12_4C-80per_4C_CH5.csv\n",
      "Colonnes supprimées de : 2017-05-12_4C-80per_4C_CH6.csv\n",
      "Colonnes supprimées de : 2017-05-12_4_4C-80per_4_4C_CH7.csv\n",
      "Colonnes supprimées de : 2017-05-12_4_8C-80per_4_8C_CH10.csv\n",
      "Colonnes supprimées de : 2017-05-12_4_8C-80per_4_8C_CH9.csv\n",
      "Colonnes supprimées de : 2017-05-12_5_4C-80per_5_4C_CH11.csv\n",
      "Colonnes supprimées de : 2017-05-12_5_4C-80per_5_4C_CH12.csv\n",
      "Colonnes supprimées de : 2017-06-30_4_8C-80per_4_8C_CH4.csv\n",
      "Colonnes supprimées de : 2017-06-30_4_8C-80per_4_8C_CH7.csv\n",
      "Colonnes supprimées de : 2017-06-30_4_8C-80per_4_8C_CH8.csv\n",
      "Colonnes supprimées de : 2018-04-12_4_8C_80per_4_8C_newstructure_CH1.csv\n",
      "Colonnes supprimées de : 2018-04-12_4_8C_80per_4_8C_newstructure_CH17.csv\n",
      "Colonnes supprimées de : 2018-04-12_4_8C_80per_4_8C_newstructure_CH25.csv\n",
      "Colonnes supprimées de : 2018-04-12_4_8C_80per_4_8C_newstructure_CH9.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def remove_columns_from_csv(directory, columns_to_remove):\n",
    "    # Lister tous les fichiers CSV dans le répertoire donné\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Parcourir chaque fichier CSV\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(directory, csv_file)\n",
    "        \n",
    "        # Lire le fichier CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Vérifier et supprimer les colonnes spécifiques si elles existent\n",
    "        df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)\n",
    "        \n",
    "        # Enregistrer le fichier CSV modifié (remplace le fichier original)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Colonnes supprimées de : {csv_file}\")\n",
    "\n",
    "directory = r'C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs'\n",
    "\n",
    "\n",
    "columns_to_remove = ['Test_Time', 'DateTime', 'Step_Time', 'Step_Index', 'Aux_Voltage','Data_Point','Charge_Capacity','Charge_Energy','Discharge_Energy']\n",
    "\n",
    "\n",
    "remove_columns_from_csv(directory, columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lignes filtrées dans : 2017-05-12_3_6C-80per_3_6C_CH1.csv\n",
      "lignes filtrées dans : 2017-05-12_3_6C-80per_3_6C_CH2.csv\n",
      "lignes filtrées dans : 2017-05-12_3_6C-80per_3_6C_CH3.csv\n",
      "lignes filtrées dans : 2017-05-12_4C-80per_4C_CH5.csv\n",
      "lignes filtrées dans : 2017-05-12_4C-80per_4C_CH6.csv\n",
      "lignes filtrées dans : 2017-05-12_4_4C-80per_4_4C_CH7.csv\n",
      "lignes filtrées dans : 2017-05-12_4_8C-80per_4_8C_CH10.csv\n",
      "lignes filtrées dans : 2017-05-12_4_8C-80per_4_8C_CH9.csv\n",
      "lignes filtrées dans : 2017-05-12_5_4C-80per_5_4C_CH11.csv\n",
      "lignes filtrées dans : 2017-05-12_5_4C-80per_5_4C_CH12.csv\n",
      "lignes filtrées dans : 2017-06-30_4_8C-80per_4_8C_CH4.csv\n",
      "lignes filtrées dans : 2017-06-30_4_8C-80per_4_8C_CH7.csv\n",
      "lignes filtrées dans : 2017-06-30_4_8C-80per_4_8C_CH8.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH1.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH17.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH25.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH9.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def remove_rows(directory):\n",
    "    ## Lister tous les fichiers CSV dans le répertoire donné \n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv') ]\n",
    "\n",
    "    # Parcourir chaque fichier CSV\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(directory, csv_file)\n",
    "        \n",
    "        # Lire le fichier CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "      \n",
    "        \n",
    "        # Supprimer les lignes où Cycle_Index est égal à 0\n",
    "        df = df[df['Cycle_Index'] != 0]\n",
    "        \n",
    "        # Enregistrer le fichier CSV modifié (remplace le fichier original)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"lignes filtrées dans : {csv_file}\")\n",
    "\n",
    "# Répertoire contenant les fichiers CSV\n",
    "directory = r'C:\\Users\\pc\\Desktop\\data\\all batchs'  # Remplacez par votre chemin\n",
    "\n",
    "\n",
    "# Appel de la fonction\n",
    "remove_rows(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_3_6C-80per_3_6C_CH1.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_3_6C-80per_3_6C_CH2.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_3_6C-80per_3_6C_CH3.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_4C-80per_4C_CH5.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_4C-80per_4C_CH6.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_4_4C-80per_4_4C_CH7.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_4_8C-80per_4_8C_CH10.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_4_8C-80per_4_8C_CH9.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_5_4C-80per_5_4C_CH11.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-05-12_5_4C-80per_5_4C_CH12.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-06-30_4_8C-80per_4_8C_CH4.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-06-30_4_8C-80per_4_8C_CH7.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2017-06-30_4_8C-80per_4_8C_CH8.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH1.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH17.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH25.csv\n",
      "Colonne 'Cycle_Index' décrémentée dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH9.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "# Parcourir chaque fichier CSV\n",
    "for csv_file in csv_files:\n",
    "    # Construire le chemin complet du fichier\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    \n",
    "    # Lire le fichier CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    \n",
    "    if 'Cycle_Index' in df.columns:\n",
    "        df['Cycle_Index'] = df['Cycle_Index'] - 1\n",
    "        \n",
    "        # Enregistrer le fichier CSV modifié (remplace le fichier original)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Colonne 'Cycle_Index' décrémentée dans : {csv_file}\")\n",
    "    else:\n",
    "        print(f\"Colonne 'Cycle_Index' non trouvée dans : {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enlever le derniers cycle des donnee de 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH1.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH17.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH25.csv\n",
      "lignes filtrées dans : 2018-04-12_4_8C_80per_4_8C_newstructure_CH9.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def remove_rows(directory):\n",
    "    # Lister tous les fichiers CSV dans le répertoire donné \n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv') and f.startswith('2018')]\n",
    "\n",
    "    # Parcourir chaque fichier CSV\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(directory, csv_file)\n",
    "        \n",
    "        # Lire le fichier CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        derniere_valeur = df['Cycle_Index'].iloc[-1]\n",
    "\n",
    "        # Supprimer les lignes où Cycle_Index est égal à 0\n",
    "        df = df[df['Cycle_Index'] != derniere_valeur]\n",
    "        \n",
    "        # Enregistrer le fichier CSV modifié (remplace le fichier original)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"lignes filtrées dans : {csv_file}\")\n",
    "\n",
    "# Répertoire contenant les fichiers CSV\n",
    "directory = r'C:\\Users\\pc\\Desktop\\data\\all batchs'  # Remplacez par votre chemin\n",
    "# Appel de la fonction\n",
    "remove_rows(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des exeption restante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "file_path='C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-05-12_3_6C-80per_3_6C_CH1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Suppression du cycle 11\n",
    "df = df[df['Cycle_Index'] != 11]\n",
    "\n",
    "# Décrémenter tous les Cycle_Index supérieurs à 11\n",
    "df.loc[df['Cycle_Index'] > 11, 'Cycle_Index'] -= 1\n",
    "df.to_csv(file_path, index=False)\n",
    "df = df[(df['Cycle_Index'] != 1189)&(df['Cycle_Index']!=1188)]\n",
    "\n",
    "# Décrémenter tous les Cycle_Index supérieurs à 11\n",
    "df.loc[df['Cycle_Index'] > 1189, 'Cycle_Index'] -= 2\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "file_path='C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-05-12_3_6C-80per_3_6C_CH2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[(df['Cycle_Index'] != 1179)&(df['Cycle_Index']!=1178)]\n",
    "\n",
    "# Décrémenter tous les Cycle_Index supérieurs à 11\n",
    "df.loc[df['Cycle_Index'] > 1179, 'Cycle_Index'] -= 2\n",
    "df.to_csv(file_path, index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "file_path='C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-05-12_3_6C-80per_3_6C_CH3.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[(df['Cycle_Index'] != 1177)&(df['Cycle_Index']!=1176)]\n",
    "\n",
    "# Décrémenter tous les Cycle_Index supérieurs à 11\n",
    "df.loc[df['Cycle_Index'] > 1177, 'Cycle_Index'] -= 2\n",
    "df.to_csv(file_path, index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "file_path='C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-05-12_4_4C-80per_4_4C_CH7.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[(df['Cycle_Index'] != 908)]\n",
    "\n",
    "# Décrémenter tous les Cycle_Index supérieurs à 11\n",
    "df.loc[df['Cycle_Index'] >908, 'Cycle_Index'] -= 1\n",
    "df.to_csv(file_path, index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle_Index où le maximum de Discharge Capacity est inférieur à 0.95 :\n",
      "Index([908.0], dtype='float64', name='Cycle_Index')\n"
     ]
    }
   ],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin du fichier CSV\n",
    "file_path = 'C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-05-12_4_4C-80per_4_4C_CH7.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filtrer les lignes où 'Cycle_Index' est inférieur à 1500\n",
    "filtered_df = df[df['Cycle_Index'] < 1000]\n",
    "\n",
    "# Calculer le maximum de 'Discharge_Capacity' par 'Cycle_Index' dans les cycles filtrés\n",
    "max_discharge_capacity = filtered_df.groupby('Cycle_Index')['Discharge_Capacity'].max()\n",
    "\n",
    "# Filtrer les 'Cycle_Index' où le maximum de 'Discharge_Capacity' est inférieur à 0.95\n",
    "cycles_below_095 = max_discharge_capacity[max_discharge_capacity < 0.925].index\n",
    "\n",
    "# Afficher les 'Cycle_Index' correspondants\n",
    "print(\"Cycle_Index où le maximum de Discharge Capacity est inférieur à 0.95 :\")\n",
    "print(cycles_below_095)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supprimer les cycles ou max discharge capacity est inférieur a 0.880000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycles filtrés et lissés dans : 2017-05-12_3_6C-80per_3_6C_CH2.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_3_6C-80per_3_6C_CH3.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_4C-80per_4C_CH5.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_4C-80per_4C_CH6.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_4_4C-80per_4_4C_CH7.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_4_8C-80per_4_8C_CH10.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_4_8C-80per_4_8C_CH9.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_5_4C-80per_5_4C_CH11.csv\n",
      "Cycles filtrés et lissés dans : 2017-05-12_5_4C-80per_5_4C_CH12.csv\n",
      "Cycles filtrés et lissés dans : 2017-06-30_4_8C-80per_4_8C_CH4.csv\n",
      "Cycles filtrés et lissés dans : 2017-06-30_4_8C-80per_4_8C_CH7.csv\n",
      "Cycles filtrés et lissés dans : 2017-06-30_4_8C-80per_4_8C_CH8.csv\n",
      "Cycles filtrés et lissés dans : 2018-04-12_4_8C_80per_4_8C_CH1.csv\n",
      "Cycles filtrés et lissés dans : 2018-04-12_4_8C_80per_4_8C_CH17.csv\n",
      "Cycles filtrés et lissés dans : 2018-04-12_4_8C_80per_4_8C_CH25.csv\n",
      "Cycles filtrés et lissés dans : 2018-04-12_4_8C_80per_4_8C_CH9.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def remove_cycles_with_low_discharge(directory, threshold=0.830000, window=50):\n",
    "    # Lister tous les fichiers CSV dans le répertoire donné\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Parcourir chaque fichier CSV\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(directory, csv_file)\n",
    "\n",
    "        # Lire le fichier CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Calculer le maximum de Discharge Capacity par Cycle_Index\n",
    "        max_discharge_capacity = df.groupby('Cycle_Index')['Discharge_Capacity'].max()\n",
    "\n",
    "        # Appliquer une moyenne glissante (moving average) pour lisser les données\n",
    "        smoothed_capacity = max_discharge_capacity.rolling(window=window, center=True).mean()\n",
    "\n",
    "        # Remplacer les NaN générés par le lissage par les valeurs originales\n",
    "        smoothed_capacity.fillna(max_discharge_capacity, inplace=True)\n",
    "\n",
    "        # Filtrer les Cycle_Index où le maximum de Discharge Capacity lissé est supérieur ou égal au seuil\n",
    "        valid_cycles = smoothed_capacity[smoothed_capacity >= threshold].index\n",
    "\n",
    "        # Garder seulement les lignes dont le Cycle_Index est dans les cycles valides\n",
    "        df_filtered = df[df['Cycle_Index'].isin(valid_cycles)]\n",
    "\n",
    "        # Enregistrer le fichier CSV modifié (remplace le fichier original)\n",
    "        df_filtered.to_csv(file_path, index=False)\n",
    "        print(f\"Cycles filtrés et lissés dans : {csv_file}\")\n",
    "\n",
    "# Répertoire contenant les fichiers CSV\n",
    "directory = r'C:\\Users\\pc\\Desktop\\data\\all batchs'  # Remplacez par votre chemin\n",
    "\n",
    "# Appel de la fonction avec une fenêtre de lissage de 5\n",
    "remove_cycles_with_low_discharge(directory, threshold=0.83, window=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin vers le répertoire contenant les fichiers CSV\n",
    "directory = r'C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs'\n",
    "\n",
    "# Lister tous les fichiers CSV dans le répertoire\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Ouvrir un fichier texte pour écrire les résultats\n",
    "with open('output_data_types.txt', 'w') as f:\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        f.write(f\"\\n\\nFichier: {file}\\n\")\n",
    "        \n",
    "        # Charger le fichier CSV dans un DataFrame Pandas\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        \n",
    "        # Écrire les types de colonnes dans le fichier texte\n",
    "        f.write(\"Types de données :\\n\")\n",
    "        f.write(df.dtypes.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # Vérifier s'il y a des valeurs manquantes dans chaque colonne\n",
    "        missing_values = df.isnull().sum()\n",
    "        missing_values_columns = missing_values[missing_values > 0]\n",
    "\n",
    "        # Écrire les colonnes avec des valeurs manquantes dans le fichier texte\n",
    "        if not missing_values_columns.empty:\n",
    "            f.write(\"Colonnes avec des valeurs manquantes :\\n\")\n",
    "            f.write(missing_values_columns.to_string())\n",
    "        else:\n",
    "            f.write(\"Aucune valeur manquante dans les colonnes.\\n\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplacer les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#remplacer les valeurs manquantes\n",
    "for csv_file in csv_files:\n",
    "    # Construire le chemin complet du fichier\n",
    "    file_path = os.path.join(directory, csv_file)\n",
    "    \n",
    "    # Lire le fichier CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Remplir les valeurs manquantes\n",
    "    df=df.bfill()\n",
    "    df.to_csv(file_path, index=False)\n",
    "'''\n",
    "import pandas as pd\n",
    "import builtins\n",
    "\n",
    "directory = r'C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-05-12_3_6C-80per_3_6C_CH2.csv' \n",
    "df = pd.read_csv(directory)\n",
    "\n",
    "zero_indices = df[df['Internal_Resistance'] == 0].index\n",
    "window_size = 10\n",
    "\n",
    "for idx in zero_indices:\n",
    "    # Définir la fenêtre autour de l'indice courant\n",
    "    start_idx = builtins.max(0, idx - window_size // 2)\n",
    "    end_idx = builtins.min(len(df), idx + window_size // 2 + 1)\n",
    "    \n",
    "    # Extraire les valeurs proches (en excluant les zéros eux-mêmes)\n",
    "    nearby_values = df['Internal_Resistance'].iloc[start_idx:end_idx]\n",
    "    nearby_values = nearby_values[nearby_values != 0]\n",
    "    \n",
    "    # Calculer la moyenne des valeurs proches et remplacer la valeur\n",
    "    if not nearby_values.empty:\n",
    "        df.at[idx, 'Internal_Resistance'] = nearby_values.mean()\n",
    "\n",
    "# Sauvegarder les modifications dans le fichier CSV\n",
    "df.to_csv(directory, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemins des fichiers\n",
    "file_path_1 = r'C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs\\\\2017-06-30_4_8C-80per_4_8C_CH8.csv'\n",
    "\n",
    "\n",
    "# Lire les fichiers CSV\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "\n",
    "\n",
    "# Remplacer les 400 premières valeurs de 'Internal_Resistance' dans df1 par celles de df2\n",
    "df1.loc[:399, 'Internal_Resistance'] \n",
    "\n",
    "# Enregistrer le fichier modifié\n",
    "#df1.to_csv(file_path_1, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Chemin vers le répertoire contenant les fichiers CSV\n",
    "data_path = r'C:\\\\Users\\\\pc\\\\Desktop\\\\data\\\\all batchs'\n",
    "\n",
    "# Lister tous les fichiers CSV dans le répertoire donné\n",
    "csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(data_path, csv_file)\n",
    "    \n",
    "    # Lire le fichier CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ajouter une colonne 'Data_Point' avec des valeurs de 0 à n-1 (ou autre logique si nécessaire)\n",
    "    df['Data_Point'] = range(len(df))\n",
    "    \n",
    "    # Séparer les colonnes à normaliser et celles à conserver\n",
    "    cols_to_normalize = [col for col in df.columns if col not in ['Cycle_Index', 'Data_Point']]\n",
    "    \n",
    "    # Appliquer la normalisation sur les colonnes sélectionnées\n",
    "    scaler = MinMaxScaler()\n",
    "    df[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])\n",
    "    \n",
    "    # Sauvegarder le DataFrame modifié dans le fichier original\n",
    "    df.to_csv(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
